{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/preet/Downloads/Data/genres_original/data/data_10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH, \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network topology\n",
    "model = keras.Sequential([\n",
    "keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "    \n",
    "keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "keras.layers.Dropout(0.3),\n",
    "    \n",
    "keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "keras.layers.Dropout(0.3),\n",
    "    \n",
    "keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "keras.layers.Dropout(0.3),\n",
    "    \n",
    "keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 1690)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               865792    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,014,218\n",
      "Trainable params: 1,014,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 27.1771 - accuracy: 0.1803 - val_loss: 4.3227 - val_accuracy: 0.2969\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 7.8015 - accuracy: 0.1963 - val_loss: 3.3477 - val_accuracy: 0.2551\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 5.0664 - accuracy: 0.1966 - val_loss: 3.2715 - val_accuracy: 0.2812\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 4.1714 - accuracy: 0.1986 - val_loss: 3.3322 - val_accuracy: 0.2326\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 3.8320 - accuracy: 0.2151 - val_loss: 3.2258 - val_accuracy: 0.2880\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 3.6075 - accuracy: 0.2327 - val_loss: 3.1764 - val_accuracy: 0.3038\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 3.5184 - accuracy: 0.2287 - val_loss: 3.1872 - val_accuracy: 0.2969\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.4371 - accuracy: 0.2445 - val_loss: 3.1416 - val_accuracy: 0.3209\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.3751 - accuracy: 0.2473 - val_loss: 3.1244 - val_accuracy: 0.3069\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.3232 - accuracy: 0.2653 - val_loss: 3.0692 - val_accuracy: 0.3455\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.2607 - accuracy: 0.2778 - val_loss: 3.0590 - val_accuracy: 0.3444\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.2497 - accuracy: 0.2841 - val_loss: 3.0367 - val_accuracy: 0.3550\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.1636 - accuracy: 0.3020 - val_loss: 3.0172 - val_accuracy: 0.3553\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.1477 - accuracy: 0.3069 - val_loss: 2.9971 - val_accuracy: 0.3518\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.1149 - accuracy: 0.3008 - val_loss: 2.9713 - val_accuracy: 0.3650\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 3.0546 - accuracy: 0.3284 - val_loss: 2.9334 - val_accuracy: 0.3859\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 3.0380 - accuracy: 0.3262 - val_loss: 2.9353 - val_accuracy: 0.3827\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.0226 - accuracy: 0.3299 - val_loss: 2.8517 - val_accuracy: 0.4005\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 3.0102 - accuracy: 0.3307 - val_loss: 2.8709 - val_accuracy: 0.4116\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.9474 - accuracy: 0.3498 - val_loss: 2.8550 - val_accuracy: 0.4162\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.9268 - accuracy: 0.3616 - val_loss: 2.8232 - val_accuracy: 0.4142\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.8868 - accuracy: 0.3596 - val_loss: 2.8102 - val_accuracy: 0.4282\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.8733 - accuracy: 0.3690 - val_loss: 2.7878 - val_accuracy: 0.4374\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.8264 - accuracy: 0.3824 - val_loss: 2.7614 - val_accuracy: 0.4299\n",
      "Epoch 25/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.7804 - accuracy: 0.3886 - val_loss: 2.7070 - val_accuracy: 0.4339\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.7671 - accuracy: 0.3965 - val_loss: 2.7164 - val_accuracy: 0.4488\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.7409 - accuracy: 0.3945 - val_loss: 2.6788 - val_accuracy: 0.4571\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.7173 - accuracy: 0.4076 - val_loss: 2.6763 - val_accuracy: 0.4499\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.6911 - accuracy: 0.4142 - val_loss: 2.6244 - val_accuracy: 0.4662\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.6467 - accuracy: 0.4230 - val_loss: 2.6032 - val_accuracy: 0.4408\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.6365 - accuracy: 0.4243 - val_loss: 2.5618 - val_accuracy: 0.4519\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.5969 - accuracy: 0.4260 - val_loss: 2.5716 - val_accuracy: 0.4462\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.5681 - accuracy: 0.4319 - val_loss: 2.6086 - val_accuracy: 0.4448\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.5284 - accuracy: 0.4465 - val_loss: 2.5352 - val_accuracy: 0.4714\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.4874 - accuracy: 0.4496 - val_loss: 2.4858 - val_accuracy: 0.4900\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.4592 - accuracy: 0.4561 - val_loss: 2.4971 - val_accuracy: 0.4817\n",
      "Epoch 37/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.4198 - accuracy: 0.4706 - val_loss: 2.4745 - val_accuracy: 0.4720\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.3968 - accuracy: 0.4672 - val_loss: 2.4222 - val_accuracy: 0.4840\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.3565 - accuracy: 0.4753 - val_loss: 2.4334 - val_accuracy: 0.4731\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.3172 - accuracy: 0.4851 - val_loss: 2.4051 - val_accuracy: 0.4954\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.2814 - accuracy: 0.4861 - val_loss: 2.3691 - val_accuracy: 0.4980\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.2668 - accuracy: 0.4917 - val_loss: 2.3521 - val_accuracy: 0.4920\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.2165 - accuracy: 0.4884 - val_loss: 2.3075 - val_accuracy: 0.5069\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.1966 - accuracy: 0.5043 - val_loss: 2.2832 - val_accuracy: 0.5049\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.1524 - accuracy: 0.5077 - val_loss: 2.2908 - val_accuracy: 0.5074\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.1275 - accuracy: 0.5205 - val_loss: 2.2600 - val_accuracy: 0.5157\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.0906 - accuracy: 0.5260 - val_loss: 2.2362 - val_accuracy: 0.5152\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 2.0436 - accuracy: 0.5282 - val_loss: 2.2603 - val_accuracy: 0.5051\n",
      "Epoch 49/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 2.0238 - accuracy: 0.5361 - val_loss: 2.2016 - val_accuracy: 0.5277\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 1.9744 - accuracy: 0.5519 - val_loss: 2.1839 - val_accuracy: 0.5260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
